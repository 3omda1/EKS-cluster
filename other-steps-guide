1 - Get access key and secret from security credentials under my account menu
aws configure  ---> at your terminal
put access key, secret and your default region (us-east-1 in our case)

2 - Create VPC for worker nodes from cloud formation service
S3 bucket link
https://s3.us-west-2.amazonaws.com/amazon-eks/cloudformation/2020-10-29/amazon-eks-vpc-private-subnets.yaml

3 - Create IAM role for EKS to allows access to other AWS service resources that are required to operate clusters managed by EKS.
EKS - Cluster role for EKS service (according to AWS documentation )

4 - Open the Amazon EKS console at https://console.aws.amazon.com/eks/home#/clusters.
Create your cluster

5 - connect kubectl with your EKS cluster
aws eks update-kubeconfig --name ThinkOn-EKS-Cluster

6 - Create IAM role for node group (EC2 instances) because kubelet in the worker nodes need permission to talk to other aws services (We create IAM role for the EC2 because the node group is created from bunch of EC2 instances)
AMAZON EKS WORKER NODE POLICY (access to EC2 and EKS in read mode)
AMAZON EC2 CONTANER REGISTERY READ ONLY (to pull images from the ECR)
AMAZON EKS CNI POLICY (to interact with other EC2 instances)

7 - Create your node group

8 - Deploy our K8S YAML files (including metrics server)

9 - connect to our mongo express deployment on port 8081

10 - Test the HPA
ab -n 10000 -c 100 http://a7397f82ab55d46c09ff1c2d9051f1f2-1466518389.us-east-1.elb.amazonaws.com:8081/


To perform a rolling update:
kubectl set image deployment/my-deployment-name container-name=new-container-image 

To perform a rollback:
kubectl rollout undo deployment/my-deployment-name

Documentation
https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.htmlprerequisites
-------------------------------------------------------------------------------------------------------------------------------
To allow the development team to deploy and rollback Kubernetes resources but restrict them from running certain commands, we can use Kubernetes Role-Based Access Control (RBAC) to manage access to the Kubernetes cluster.
Here is a RBAC Role that allows deployment and rollback of resources but restricts access to certain commands.
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: deployer-role
rules:
- apiGroups: ["apps", "extensions", ""]
  resources: ["deployments", "replicasets", "pods"]
  verbs: ["create", "delete", "patch", "update", "get", "list", "watch", "rollback"]
- apiGroups: [""]
  resources: ["services", "configmaps", "secrets"]
  verbs: ["get", "list", "watch"]


Create a Kubernetes ServiceAccount for the development team:
apiVersion: v1
kind: ServiceAccount
metadata:
  name: deployer
  namespace: default


Bind the RBAC Role to the ServiceAccount:
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: deployer-rolebinding
  namespace: default
subjects:
- kind: ServiceAccount
  name: deployer
  namespace: default
roleRef:
  kind: Role
  name: deployer-role
  apiGroup: rbac.authorization.k8s.io

Now, the development team can use the "deployer" ServiceAccount to deploy and rollback resources in the default namespace, but they will be restricted from running certain commands.


--------------------------------------------------------------------------------------------------------------------------------
Bonus:
To apply the configs to multiple environments, such as staging and production, you could use Kubernetes' namespaces to separate the resources and configurations for each environment. You could create a namespace for staging and a namespace for production, and then apply the same YAML files to both namespaces with different configurations for each environment.
AS shown below:
1 - Create a namespace for staging:
apiVersion: v1
kind: Namespace
metadata:
  name: staging


2 - Create a namespace for production:
apiVersion: v1
kind: Namespace
metadata:
  name: production

3 - Apply the YAML files for the deployments, HPA, and RBAC to both namespaces:
kubectl apply -f deployment.yaml -n staging
kubectl apply -f deployment.yaml -n production

kubectl apply -f hpa.yaml -n staging
kubectl apply -f hpa.yaml -n production

kubectl apply -f rbac.yaml -n staging
kubectl apply -f rbac.yaml -n production
--------------------------------------------------------------------------------------------------------------------------------